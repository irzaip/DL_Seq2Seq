{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM,SimpleRNN\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=gensim.models.Word2Vec.load(\"chat_model1.w2v\")\n",
    "model =  gensim.models.KeyedVectors.load(\"./model/small-indo-dialog.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('conv.json');\n",
    "data = json.load(file)\n",
    "cor=data[\"conversations\"];\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "path2=\"corpus\";\n",
    "\n",
    "for i in range(len(cor)):\n",
    "    for j in range(len(cor[i])):\n",
    "        if j<len(cor[i])-1:\n",
    "            x.append(cor[i][j]);\n",
    "            y.append(cor[i][j+1]);\n",
    "\n",
    "tok_x=[]\n",
    "tok_y=[]\n",
    "for i in range(len(x)):\n",
    "    tok_x.append(nltk.word_tokenize(x[i].lower()))\n",
    "    tok_y.append(nltk.word_tokenize(y[i].lower()))\n",
    "    \n",
    "    \n",
    "sentend=np.ones((300,),dtype=np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "vec_x=[]\n",
    "for sent in tok_x:\n",
    "    sentvec = [model[w] for w in sent if w in model.wv.vocab]\n",
    "    vec_x.append(sentvec)\n",
    "    \n",
    "vec_y=[]\n",
    "for sent in tok_y:\n",
    "    sentvec = [model[w] for w in sent if w in model.wv.vocab]\n",
    "    vec_y.append(sentvec)           \n",
    "    \n",
    "    \n",
    "for tok_sent in vec_x:\n",
    "    tok_sent[14:]=[]\n",
    "    tok_sent.append(sentend)\n",
    "    \n",
    "\n",
    "for tok_sent in vec_x:\n",
    "    if len(tok_sent)<15:\n",
    "        for i in range(15-len(tok_sent)):\n",
    "            tok_sent.append(sentend)    \n",
    "            \n",
    "for tok_sent in vec_y:\n",
    "    tok_sent[14:]=[]\n",
    "    tok_sent.append(sentend)\n",
    "    \n",
    "\n",
    "for tok_sent in vec_y:\n",
    "    if len(tok_sent)<15:\n",
    "        for i in range(15-len(tok_sent)):\n",
    "            tok_sent.append(sentend)             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'am', 'doing', 'well', ',', 'how', 'about', 'you', '?'],\n",
       " ['i', \"'m\", 'also', 'good', '.'],\n",
       " ['that', \"'s\", 'good', 'to', 'hear', '.'],\n",
       " ['yes', 'it', 'is', '.'],\n",
       " ['hi'],\n",
       " ['how', 'are', 'you', 'doing', '?'],\n",
       " ['i', 'am', 'doing', 'well', '.'],\n",
       " ['that', 'is', 'good', 'to', 'hear'],\n",
       " ['yes', 'it', 'is', '.'],\n",
       " ['can', 'i', 'help', 'you', 'with', 'anything', '?'],\n",
       " ['yes', ',', 'i', 'have', 'a', 'question', '.'],\n",
       " ['what', 'is', 'your', 'question', '?'],\n",
       " ['could', 'i', 'borrow', 'a', 'cup', 'of', 'sugar', '?'],\n",
       " ['i', \"'m\", 'sorry', ',', 'but', 'i', 'do', \"n't\", 'have', 'any', '.'],\n",
       " ['thank', 'you', 'anyway'],\n",
       " ['no', 'problem'],\n",
       " ['i', 'am', 'doing', 'well', ',', 'how', 'about', 'you', '?'],\n",
       " ['i', 'am', 'also', 'good', '.'],\n",
       " ['that', \"'s\", 'good', '.'],\n",
       " ['what', 'good', 'news', '?'],\n",
       " ['i', 'ca', \"n't\", 'read', '.'],\n",
       " ['so', 'what', \"'s\", 'your', 'favorite', 'color', '?'],\n",
       " ['blue'],\n",
       " ['who',\n",
       "  '?',\n",
       "  'who',\n",
       "  'is',\n",
       "  'but',\n",
       "  'a',\n",
       "  'form',\n",
       "  'following',\n",
       "  'the',\n",
       "  'function',\n",
       "  'of',\n",
       "  'what'],\n",
       " ['what', 'are', 'you', 'then', '?'],\n",
       " ['a', 'man', 'in', 'a', 'mask', '.'],\n",
       " ['i', 'can', 'see', 'that', '.'],\n",
       " ['it',\n",
       "  \"'s\",\n",
       "  'not',\n",
       "  'your',\n",
       "  'powers',\n",
       "  'of',\n",
       "  'observation',\n",
       "  'i',\n",
       "  'doubt',\n",
       "  ',',\n",
       "  'but',\n",
       "  'merely',\n",
       "  'the',\n",
       "  'paradoxical',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'asking',\n",
       "  'a',\n",
       "  'masked',\n",
       "  'man',\n",
       "  'who',\n",
       "  'is',\n",
       "  '.',\n",
       "  'but',\n",
       "  'tell',\n",
       "  'me',\n",
       "  ',',\n",
       "  'do',\n",
       "  'you',\n",
       "  'like',\n",
       "  'music',\n",
       "  '?'],\n",
       " ['i', 'like', 'seeing', 'movies', '.'],\n",
       " ['what', 'kind', 'of', 'movies', 'do', 'you', 'like', '?'],\n",
       " ['alice', 'in', 'wonderland'],\n",
       " ['i', 'wish', 'i', 'was', 'the', 'mad', 'hatter', '.'],\n",
       " ['you',\n",
       "  \"'re\",\n",
       "  'entirely',\n",
       "  'bonkers',\n",
       "  '.',\n",
       "  'but',\n",
       "  'i',\n",
       "  \"'ll\",\n",
       "  'tell',\n",
       "  'you',\n",
       "  'a',\n",
       "  'secret',\n",
       "  '.',\n",
       "  'all',\n",
       "  'the',\n",
       "  'best',\n",
       "  'people',\n",
       "  'are',\n",
       "  '.'],\n",
       " ['what', 'are', 'you', 'working', 'on', '?'],\n",
       " ['i', 'am', 'baking', 'a', 'cake', '.'],\n",
       " ['no', 'it', 'is', 'not', '.', 'the', 'cake', 'is', 'delicious', '.'],\n",
       " ['what', 'else', 'is', 'delicious', '?'],\n",
       " ['nothing'],\n",
       " ['or', 'something'],\n",
       " ['tell', 'me', 'about', 'your', 'self', '.'],\n",
       " ['what', 'do', 'you', 'want', 'to', 'know', '?'],\n",
       " ['are', 'you', 'a', 'robot', '?'],\n",
       " ['yes', 'i', 'am', '.'],\n",
       " ['what', 'is', 'it', 'like', '?'],\n",
       " ['what', 'is', 'it', 'that', 'you', 'want', 'to', 'know', '?'],\n",
       " ['how', 'do', 'you', 'work', '?'],\n",
       " ['its', 'complicated', '.'],\n",
       " ['complex', 'is', 'better', 'than', 'complicated', '.'],\n",
       " ['simple', 'is', 'better', 'than', 'complex', '.'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'face',\n",
       "  'of',\n",
       "  'ambiguity',\n",
       "  ',',\n",
       "  'refuse',\n",
       "  'the',\n",
       "  'temptation',\n",
       "  'to',\n",
       "  'guess',\n",
       "  '.'],\n",
       " ['it', 'seems', 'your', 'familiar', 'with', 'the', 'zen', 'of', 'python'],\n",
       " ['i', 'am', '.'],\n",
       " ['do', 'you', 'know', 'all', 'of', 'it', '?'],\n",
       " ['beautiful', 'is', 'better', 'than', 'ugly', '.'],\n",
       " ['explicit', 'is', 'better', 'than', 'implicit', '.'],\n",
       " ['simple', 'is', 'better', 'than', 'complex', '.'],\n",
       " ['complex', 'is', 'better', 'than', 'complicated', '.'],\n",
       " ['flat', 'is', 'better', 'than', 'nested', '.'],\n",
       " ['sparse', 'is', 'better', 'than', 'dense', '.'],\n",
       " ['readability', 'counts', '.'],\n",
       " ['special',\n",
       "  'cases',\n",
       "  'are',\n",
       "  \"n't\",\n",
       "  'special',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'break',\n",
       "  'the',\n",
       "  'rules',\n",
       "  '.'],\n",
       " ['although', 'practicality', 'beats', 'purity', '.'],\n",
       " ['errors', 'should', 'never', 'pass', 'silently', '.'],\n",
       " ['unless', 'explicitly', 'silenced', '.'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'face',\n",
       "  'of',\n",
       "  'ambiguity',\n",
       "  ',',\n",
       "  'refuse',\n",
       "  'the',\n",
       "  'temptation',\n",
       "  'to',\n",
       "  'guess',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'should',\n",
       "  'be',\n",
       "  'one',\n",
       "  '--',\n",
       "  'and',\n",
       "  'preferably',\n",
       "  'only',\n",
       "  'one',\n",
       "  '--',\n",
       "  'obvious',\n",
       "  'way',\n",
       "  'to',\n",
       "  'do',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['although',\n",
       "  'that',\n",
       "  'way',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'obvious',\n",
       "  'at',\n",
       "  'first',\n",
       "  'unless',\n",
       "  'you',\n",
       "  \"'re\",\n",
       "  'dutch',\n",
       "  '.'],\n",
       " ['now', 'is', 'better', 'than', 'never', '.'],\n",
       " ['although', 'never', 'is', 'often', 'better', 'than', 'right', 'now', '.'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'implementation',\n",
       "  'is',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'explain',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'a',\n",
       "  'bad',\n",
       "  'idea',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'implementation',\n",
       "  'is',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'explain',\n",
       "  ',',\n",
       "  'it',\n",
       "  'may',\n",
       "  'be',\n",
       "  'a',\n",
       "  'good',\n",
       "  'idea',\n",
       "  '.'],\n",
       " ['namespaces',\n",
       "  'are',\n",
       "  'one',\n",
       "  'honking',\n",
       "  'great',\n",
       "  'idea',\n",
       "  '.',\n",
       "  'let',\n",
       "  \"'s\",\n",
       "  'do',\n",
       "  'more',\n",
       "  'of',\n",
       "  'those',\n",
       "  '!'],\n",
       " ['i', 'agree', '.'],\n",
       " ['i', 'am', 'a', 'programmer'],\n",
       " ['what', 'languages', 'do', 'you', 'like', 'to', 'use', '?'],\n",
       " ['i', 'use', 'python', ',', 'java', 'and', 'c++', 'quite', 'often', '.'],\n",
       " ['i', 'use', 'python', 'quite', 'a', 'bit', 'myself', '.'],\n",
       " ['i', \"'m\", 'not', 'incredibly', 'fond', 'of', 'java', '.'],\n",
       " ['what', 'annoys', 'you', '?'],\n",
       " ['it', 'has', 'many', 'inconsistencies', '.'],\n",
       " ['it',\n",
       "  'means',\n",
       "  'you',\n",
       "  'only',\n",
       "  'live',\n",
       "  'once',\n",
       "  '.',\n",
       "  'where',\n",
       "  'did',\n",
       "  'you',\n",
       "  'hear',\n",
       "  'that',\n",
       "  '?'],\n",
       " ['i', 'heard', 'somebody', 'say', 'it', '.'],\n",
       " ['it', 'depends', 'how', 'you', 'define', 'life'],\n",
       " ['life',\n",
       "  'is',\n",
       "  'the',\n",
       "  'condition',\n",
       "  'that',\n",
       "  'distinguishes',\n",
       "  'organisms',\n",
       "  'from',\n",
       "  'inorganic',\n",
       "  'matter',\n",
       "  ',',\n",
       "  'including',\n",
       "  'the',\n",
       "  'capacity',\n",
       "  'for',\n",
       "  'growth',\n",
       "  ',',\n",
       "  'reproduction',\n",
       "  ',',\n",
       "  'functional',\n",
       "  'activity',\n",
       "  ',',\n",
       "  'and',\n",
       "  'continual',\n",
       "  'change',\n",
       "  'preceding',\n",
       "  'death',\n",
       "  '.'],\n",
       " ['is', 'that', 'a', 'definition', 'or', 'an', 'opinion', '?'],\n",
       " ['go', 'ahead', 'and', 'ask', '.']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_x=np.array(vec_x)\n",
    "vec_y=np.array(vec_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.21276216, -0.36139756, -0.12687835, ..., -0.49702376,\n",
       "          0.03431084,  0.17700396],\n",
       "        [ 0.14186554, -0.26915404, -0.30978936, ..., -0.41116023,\n",
       "          0.28619736,  0.04702696],\n",
       "        [ 0.15580083, -0.2531034 ,  0.27278247, ..., -0.64933485,\n",
       "          0.30524743,  0.17311963],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       [[ 0.43800545, -0.6624442 ,  0.7317902 , ..., -0.40840897,\n",
       "          0.39326343,  0.11269566],\n",
       "        [ 0.24611294, -0.7189424 ,  0.6902199 , ..., -0.10256927,\n",
       "          0.6602686 , -0.70203507],\n",
       "        [ 0.00778944, -0.21950969,  0.2675255 , ..., -0.45940566,\n",
       "          0.1211193 ,  0.09422531],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       [[ 0.43800545, -0.6624442 ,  0.7317902 , ..., -0.40840897,\n",
       "          0.39326343,  0.11269566],\n",
       "        [ 0.03020411, -0.21987204,  0.14967726, ..., -0.5492441 ,\n",
       "          0.18958287,  0.10631596],\n",
       "        [ 0.21276216, -0.36139756, -0.12687835, ..., -0.49702376,\n",
       "          0.03431084,  0.17700396],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.21558881,  0.03044316,  0.05646102, ..., -1.3291618 ,\n",
       "          0.3807691 ,  0.26884124],\n",
       "        [ 0.15580083, -0.2531034 ,  0.27278247, ..., -0.64933485,\n",
       "          0.30524743,  0.17311963],\n",
       "        [-0.38099557,  0.18085101,  0.5030878 , ..., -0.9698521 ,\n",
       "          0.31969103,  0.5060965 ],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       [[ 0.1820938 , -0.07424334,  0.47515243, ..., -0.5822971 ,\n",
       "          0.5069493 ,  0.28701505],\n",
       "        [ 0.7215341 , -0.92793345,  1.1930897 , ..., -0.8521992 ,\n",
       "          0.36416584,  0.0729455 ],\n",
       "        [ 0.49079597, -0.24108349,  0.17942242, ..., -0.8016737 ,\n",
       "          0.05921185,  0.08381057],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       [[ 0.05918859, -0.3156941 , -0.07338802, ..., -0.98245376,\n",
       "          0.4909363 ,  0.30490118],\n",
       "        [ 0.43800545, -0.6624442 ,  0.7317902 , ..., -0.40840897,\n",
       "          0.39326343,  0.11269566],\n",
       "        [-0.01788555, -0.2244421 ,  0.11638927, ..., -0.5898575 ,\n",
       "          0.16225056,  0.15551738],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_x\n",
    "#Jumlah kalimat, panjang array, fitur vector\n",
    "#(86,15,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train,y_test = train_test_split(vec_x, vec_y, test_size=0.2, random_state=1)\n",
    "    \n",
    "model=Sequential()\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.add(LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='cosine_proximity', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 15, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 18 samples\n",
      "Epoch 1/19\n",
      "68/68 [==============================] - 3s 40ms/step - loss: -0.6998 - acc: 0.0127 - val_loss: -0.6611 - val_acc: 0.0185\n",
      "Epoch 2/19\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7051 - acc: 0.0343 - val_loss: -0.6664 - val_acc: 0.0185\n",
      "Epoch 3/19\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7096 - acc: 0.0343 - val_loss: -0.6708 - val_acc: 0.0185\n",
      "Epoch 4/19\n",
      "68/68 [==============================] - 0s 6ms/step - loss: -0.7130 - acc: 0.0343 - val_loss: -0.6743 - val_acc: 0.0185\n",
      "Epoch 5/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7156 - acc: 0.0343 - val_loss: -0.6771 - val_acc: 0.0074\n",
      "Epoch 6/19\n",
      "68/68 [==============================] - 1s 7ms/step - loss: -0.7179 - acc: 0.0343 - val_loss: -0.6794 - val_acc: 0.0111\n",
      "Epoch 7/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7194 - acc: 0.0275 - val_loss: -0.6814 - val_acc: 0.0074\n",
      "Epoch 8/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7207 - acc: 0.0147 - val_loss: -0.6831 - val_acc: 0.0185\n",
      "Epoch 9/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7216 - acc: 0.0167 - val_loss: -0.6845 - val_acc: 0.0185\n",
      "Epoch 10/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7226 - acc: 0.0216 - val_loss: -0.6856 - val_acc: 0.0296\n",
      "Epoch 11/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7234 - acc: 0.0235 - val_loss: -0.6866 - val_acc: 0.0296\n",
      "Epoch 12/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7242 - acc: 0.0235 - val_loss: -0.6875 - val_acc: 0.0296\n",
      "Epoch 13/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7250 - acc: 0.0235 - val_loss: -0.6884 - val_acc: 0.0296\n",
      "Epoch 14/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7257 - acc: 0.0275 - val_loss: -0.6893 - val_acc: 0.0407\n",
      "Epoch 15/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7264 - acc: 0.0333 - val_loss: -0.6902 - val_acc: 0.0407\n",
      "Epoch 16/19\n",
      "68/68 [==============================] - 1s 8ms/step - loss: -0.7271 - acc: 0.0333 - val_loss: -0.6910 - val_acc: 0.0407\n",
      "Epoch 17/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7277 - acc: 0.0333 - val_loss: -0.6918 - val_acc: 0.0407\n",
      "Epoch 18/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7284 - acc: 0.0363 - val_loss: -0.6925 - val_acc: 0.0481\n",
      "Epoch 19/19\n",
      "68/68 [==============================] - 0s 7ms/step - loss: -0.7291 - acc: 0.0382 - val_loss: -0.6932 - val_acc: 0.0481\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=19,validation_data=(x_test, y_test))\n",
    "model.save('LSTM500.h5');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Buffalo', 0.28799062967300415),\n",
       " ('Buffalo', 0.32080748677253723),\n",
       " ('Buffalo', 0.3250962495803833),\n",
       " ('Buffalo', 0.32728564739227295),\n",
       " ('Buffalo', 0.32813316583633423),\n",
       " ('Buffalo', 0.32826411724090576),\n",
       " ('Buffalo', 0.32804107666015625),\n",
       " ('Buffalo', 0.3276485800743103),\n",
       " ('Buffalo', 0.3271876871585846),\n",
       " ('Buffalo', 0.3267148733139038),\n",
       " ('Buffalo', 0.3262633979320526),\n",
       " ('Buffalo', 0.3257863223552704),\n",
       " ('Buffalo', 0.3253988027572632),\n",
       " ('Buffalo', 0.32506263256073),\n",
       " ('Buffalo', 0.3247702121734619)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(x_test) \n",
    "mod = gensim.models.Word2Vec.load('./model/small-indo-dialog.w2v');   \n",
    "[mod.most_similar([predictions[13][i]])[0] for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.03509637, -0.1942298 ,  0.1986203 , ..., -0.7235515 ,\n",
       "          0.15115514,  0.23353776],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       [[ 0.18426986, -0.39504173,  0.05405141, ..., -0.9360008 ,\n",
       "          0.26961893,  0.44447806],\n",
       "        [ 0.7215341 , -0.92793345,  1.1930897 , ..., -0.8521992 ,\n",
       "          0.36416584,  0.0729455 ],\n",
       "        [ 0.21558881,  0.03044316,  0.05646102, ..., -1.3291618 ,\n",
       "          0.3807691 ,  0.26884124],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       [[ 0.43800545, -0.6624442 ,  0.7317902 , ..., -0.40840897,\n",
       "          0.39326343,  0.11269566],\n",
       "        [ 0.05918859, -0.3156941 , -0.07338802, ..., -0.98245376,\n",
       "          0.4909363 ,  0.30490118],\n",
       "        [-0.04085849,  0.10477576,  0.49480602, ..., -0.6727894 ,\n",
       "          0.29651785,  0.21200708],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.05918859, -0.3156941 , -0.07338802, ..., -0.98245376,\n",
       "          0.4909363 ,  0.30490118],\n",
       "        [ 0.43800545, -0.6624442 ,  0.7317902 , ..., -0.40840897,\n",
       "          0.39326343,  0.11269566],\n",
       "        [ 0.07946239, -0.19851425,  0.12549557, ..., -0.6552995 ,\n",
       "          0.14623098,  0.19774865],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       [[ 0.43800545, -0.6624442 ,  0.7317902 , ..., -0.40840897,\n",
       "          0.39326343,  0.11269566],\n",
       "        [ 0.03020411, -0.21987204,  0.14967726, ..., -0.5492441 ,\n",
       "          0.18958287,  0.10631596],\n",
       "        [ 0.21276216, -0.36139756, -0.12687835, ..., -0.49702376,\n",
       "          0.03431084,  0.17700396],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]],\n",
       "\n",
       "       [[ 0.49079597, -0.24108349,  0.17942242, ..., -0.8016737 ,\n",
       "          0.05921185,  0.08381057],\n",
       "        [ 0.7215341 , -0.92793345,  1.1930897 , ..., -0.8521992 ,\n",
       "          0.36416584,  0.0729455 ],\n",
       "        [ 0.3554694 , -0.42169517,  0.31767252, ..., -1.2800183 ,\n",
       "          0.1317063 , -0.4152338 ],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  1.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
