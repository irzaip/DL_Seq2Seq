{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM,SimpleRNN\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"e482ac1c-50cd-405d-a3ad-c38ff9461ba7\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"e482ac1c-50cd-405d-a3ad-c38ff9461ba7\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%notify\n",
    "sorted_que = np.array(pickle.load(open('sorted_que.pickle','rb')))[0:6000]\n",
    "sorted_ans = np.array(pickle.load(open('sorted_ans.pickle','rb')))[0:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_que = sorted_que.reshape(6000,1,25)\n",
    "sorted_ans = sorted_ans.reshape(6000,1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train,y_test = train_test_split(sorted_que, sorted_ans, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 1200)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train = x_train.reshape(554184,25,1)\n",
    "y_train = y_train.reshape(554184,25,1)\n",
    "x_test = x_test.reshape(138547,25,1)\n",
    "y_test = y_test.reshape(138547,25,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 1, 25)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(input_shape=(1,25), return_sequences=True, units=25,activation=\"sigmoid\", kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.add(LSTM(input_shape=(1, 25), return_sequences=True, units=25, activation=\"sigmoid\", kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "model.add(LSTM(input_shape=(1, 25), return_sequences=True, units=25 ,activation=\"sigmoid\", kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "#model.add(LSTM(input_shape=(25, 1), return_sequences=True, activation=\"sigmoid\", kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\"))\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.8, beta_2=0.998, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='cosine_proximity', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('LSTM500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_31 (LSTM)               (None, 1, 1)              108       \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 1, 1)              12        \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 1, 1)              12        \n",
      "=================================================================\n",
      "Total params: 132\n",
      "Trainable params: 132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800 samples, validate on 1200 samples\n",
      "Epoch 1/100\n",
      "4800/4800 [==============================] - 6s 1ms/step - loss: -0.9924 - acc: 0.0000e+00 - val_loss: -0.9939 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9946 - acc: 0.0000e+00 - val_loss: -0.9953 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9958 - acc: 0.0000e+00 - val_loss: -0.9963 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9966 - acc: 0.0000e+00 - val_loss: -0.9970 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "4800/4800 [==============================] - 2s 455us/step - loss: -0.9972 - acc: 0.0000e+00 - val_loss: -0.9974 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "4800/4800 [==============================] - 2s 421us/step - loss: -0.9975 - acc: 0.0000e+00 - val_loss: -0.9977 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9978 - acc: 0.0000e+00 - val_loss: -0.9978 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9979 - acc: 0.0000e+00 - val_loss: -0.9979 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "4800/4800 [==============================] - 2s 416us/step - loss: -0.9980 - acc: 0.0302 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.1479 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.2902 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 12/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.3283 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "4800/4800 [==============================] - 2s 456us/step - loss: -0.9980 - acc: 0.3708 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.3344 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.3448 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.2333 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 17/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.5756 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.1342 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.2725 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.3850 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "4800/4800 [==============================] - 2s 452us/step - loss: -0.9980 - acc: 0.3900 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.4262 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 23/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.4302 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 24/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.6025 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.5860 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "4800/4800 [==============================] - 2s 429us/step - loss: -0.9980 - acc: 0.4838 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 27/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.5494 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 28/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.5917 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 29/100\n",
      "4800/4800 [==============================] - 2s 452us/step - loss: -0.9980 - acc: 0.6154 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.7277 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 31/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.7271 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 32/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8287 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 33/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.8840 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 34/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 35/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 36/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.8790 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 37/100\n",
      "4800/4800 [==============================] - 2s 454us/step - loss: -0.9980 - acc: 0.8971 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 38/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.8835 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 39/100\n",
      "4800/4800 [==============================] - 2s 416us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 40/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 41/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8777 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 42/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.8963 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 43/100\n",
      "4800/4800 [==============================] - 2s 416us/step - loss: -0.9980 - acc: 0.8908 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 44/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.8956 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 45/100\n",
      "4800/4800 [==============================] - 2s 447us/step - loss: -0.9980 - acc: 0.9087 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 46/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8858 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 47/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 48/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.8910 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 49/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 50/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.8904 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.8906 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 52/100\n",
      "4800/4800 [==============================] - 2s 428us/step - loss: -0.9980 - acc: 0.9025 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 53/100\n",
      "4800/4800 [==============================] - 2s 445us/step - loss: -0.9980 - acc: 0.8598 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 54/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.8590 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 55/100\n",
      "4800/4800 [==============================] - 2s 421us/step - loss: -0.9980 - acc: 0.8906 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 56/100\n",
      "4800/4800 [==============================] - 2s 425us/step - loss: -0.9980 - acc: 0.8163 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "4800/4800 [==============================] - 2s 426us/step - loss: -0.9980 - acc: 0.8906 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 2s 428us/step - loss: -0.9980 - acc: 0.8971 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 59/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.8781 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 60/100\n",
      "4800/4800 [==============================] - 2s 451us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 61/100\n",
      "4800/4800 [==============================] - 2s 426us/step - loss: -0.9980 - acc: 0.9029 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 62/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 63/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 64/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 65/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.8723 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 66/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8344 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 67/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.8963 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 68/100\n",
      "4800/4800 [==============================] - 2s 456us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 69/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.8644 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 70/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8360 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 71/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 72/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 73/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.9023 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 74/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.8965 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 75/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.8975 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 76/100\n",
      "4800/4800 [==============================] - 2s 455us/step - loss: -0.9980 - acc: 0.9087 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 77/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.8902 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 78/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 79/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 80/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8842 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 81/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 82/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.8852 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 83/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 84/100\n",
      "4800/4800 [==============================] - 2s 457us/step - loss: -0.9980 - acc: 0.8417 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 85/100\n",
      "4800/4800 [==============================] - 2s 423us/step - loss: -0.9980 - acc: 0.8965 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 86/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.8485 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 87/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.8615 - val_loss: -0.9980 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.8967 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 89/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8788 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 90/100\n",
      "4800/4800 [==============================] - 2s 421us/step - loss: -0.9980 - acc: 0.8904 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 91/100\n",
      "4800/4800 [==============================] - 2s 417us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 92/100\n",
      "4800/4800 [==============================] - 2s 457us/step - loss: -0.9980 - acc: 0.9148 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 93/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8602 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 94/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8475 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 95/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.8973 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 96/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.9025 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 97/100\n",
      "4800/4800 [==============================] - 2s 418us/step - loss: -0.9980 - acc: 0.9027 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 98/100\n",
      "4800/4800 [==============================] - 2s 420us/step - loss: -0.9980 - acc: 0.9031 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 99/100\n",
      "4800/4800 [==============================] - 2s 419us/step - loss: -0.9980 - acc: 0.8967 - val_loss: -0.9980 - val_acc: 0.9192\n",
      "Epoch 100/100\n",
      "4800/4800 [==============================] - 2s 455us/step - loss: -0.9980 - acc: 0.8667 - val_loss: -0.9980 - val_acc: 0.9192\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100,validation_data=(x_test, y_test))\n",
    "model.save('LSTM500.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.19756857, 0.3401386 , 0.34009868, 0.3401112 , 0.34009886,\n",
       "         0.34010252, 0.34010497, 0.34009624, 0.34010404, 0.34009892,\n",
       "         0.34009904, 0.34009162, 0.3400926 , 0.3401027 , 0.34009942,\n",
       "         0.34010196, 0.34010112, 0.34009492, 0.3400997 , 0.34010303,\n",
       "         0.34010515, 0.34010115, 0.34009826, 0.34010142, 0.3401021 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(x_train[250]).reshape(1,1,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3185, 10031, 10030, 10030, 10030, 10030, 10030, 10030, 10030,\n",
       "        10030, 10030, 10030, 10030, 10030, 10030, 10030, 10030, 10030,\n",
       "        10030, 10030, 10030, 10030, 10030, 10030, 10030]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
